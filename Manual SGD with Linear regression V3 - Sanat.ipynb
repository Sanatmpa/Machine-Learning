{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing manual SGD on Linear regression model :\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will implement a function to manually perform <b> Stochastic Gradient Descent(SGD) </b> Optimization for Linear regression algorithm.\n",
    "\n",
    "We will use boston house prices dataset from Sklearn for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data into DF and high level analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=datasets.load_boston()\n",
    "boston_x=np.array(b.data)\n",
    "boston_y=np.array(b.target)\n",
    "boston_x1=np.nan_to_num(boston_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(boston_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>istat</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad    tax  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   ptratio   black  istat  Price  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns=['crim','zn','indus','chas','nox','rm','age','dis','rad','tax','ptratio','black','istat']\n",
    "data['Price']=boston_y\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crim       False\n",
       "zn         False\n",
       "indus      False\n",
       "chas       False\n",
       "nox        False\n",
       "rm         False\n",
       "age        False\n",
       "dis        False\n",
       "rad        False\n",
       "tax        False\n",
       "ptratio    False\n",
       "black      False\n",
       "istat      False\n",
       "Price      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crim       False\n",
       "zn         False\n",
       "indus      False\n",
       "chas       False\n",
       "nox        False\n",
       "rm         False\n",
       "age        False\n",
       "dis        False\n",
       "rad        False\n",
       "tax        False\n",
       "ptratio    False\n",
       "black      False\n",
       "istat      False\n",
       "Price      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>istat</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.593761</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.596783</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.647423</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             crim          zn       indus        chas         nox          rm  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.593761   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.596783   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.647423   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              age         dis         rad         tax     ptratio       black  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            istat       Price  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting of data into Test and Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>istat</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.03768</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.404</td>\n",
       "      <td>7.274</td>\n",
       "      <td>38.3</td>\n",
       "      <td>7.3090</td>\n",
       "      <td>2.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>392.20</td>\n",
       "      <td>6.62</td>\n",
       "      <td>34.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.24522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>5.782</td>\n",
       "      <td>71.7</td>\n",
       "      <td>4.0317</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>396.90</td>\n",
       "      <td>15.94</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>8.98296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.770</td>\n",
       "      <td>6.212</td>\n",
       "      <td>97.4</td>\n",
       "      <td>2.1222</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>377.73</td>\n",
       "      <td>17.60</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.32264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>5.942</td>\n",
       "      <td>93.5</td>\n",
       "      <td>1.9669</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>378.25</td>\n",
       "      <td>16.90</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        crim    zn  indus  chas    nox     rm   age     dis   rad    tax  \\\n",
       "198  0.03768  80.0   1.52   0.0  0.404  7.274  38.3  7.3090   2.0  329.0   \n",
       "317  0.24522   0.0   9.90   0.0  0.544  5.782  71.7  4.0317   4.0  304.0   \n",
       "356  8.98296   0.0  18.10   1.0  0.770  6.212  97.4  2.1222  24.0  666.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889   1.0  273.0   \n",
       "136  0.32264   0.0  21.89   0.0  0.624  5.942  93.5  1.9669   4.0  437.0   \n",
       "\n",
       "     ptratio   black  istat  Price  \n",
       "198     12.6  392.20   6.62   34.6  \n",
       "317     18.4  396.90  15.94   19.8  \n",
       "356     20.2  377.73  17.60   17.8  \n",
       "504     21.0  393.45   6.48   22.0  \n",
       "136     21.2  378.25  16.90   17.4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,test=train_test_split(data,test_size=0.3,random_state=33)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array(train.drop(columns='Price'))\n",
    "y_train=np.array(train['Price'])\n",
    "x_test=np.array(test.drop(columns='Price'))\n",
    "y_test=np.array(test['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_train=scaler.fit_transform(x_train)\n",
    "std_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions used : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created multiple functions here to enable modularity in code, which promotes code reusability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def W_gradient(w,b,x,y):\n",
    "    '''\n",
    "    Gradient function with respect to W\n",
    "    '''\n",
    "    w_dash=(-2/len(x))*((x.T @ (y-(x @ (w.T))-b)))\n",
    "    #print(w_dash.shape)\n",
    "    return w_dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def B_gradient(w,b,x,y):\n",
    "    '''\n",
    "    Gradient function with respect to B\n",
    "    '''\n",
    "    b_dash=((-2/len(x))*np.sum((y-(x.dot(w.T))-b)))\n",
    "    #print(b_dash.shape)\n",
    "    return b_dash\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the below one as i was testing it and is not used here.."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def update_function(w,b,r,x,y,iteration,tolerance=0.01,max_iteration=10000):\n",
    "    '''\n",
    "    To perform update function for SGD Optimization\n",
    "    '''\n",
    "    global optimal_w\n",
    "    global optimal_b\n",
    "    iteration+=1\n",
    "    k=np.random.randint(0,high=len(x),size=100) # Batch size\n",
    "    x1=x[k]\n",
    "    y1=y[k,np.newaxis]\n",
    "    #print(x1.shape)\n",
    "    #print(w.shape)\n",
    "    #print(b)\n",
    "    #e= (y[:,np.newaxis]-(x.dot(w.T))-b)\n",
    "    #if iteration<=4:\n",
    "        #print(e[10])\n",
    "    #print(e.shape)\n",
    "    w_new= w.T -(r * W_gradient(w,b,x1,y1))\n",
    "    w_new=w_new.T\n",
    "    b_new=b-r*B_gradient(w,b,x1,y1)\n",
    "    #print(w_new.shape)\n",
    "    #print(b_new)\n",
    "    \n",
    "    if(euclidean_distances(w_new,w).all() <= tolerance):\n",
    "        print(f'Converged after {iteration} Iterations.. :) ')\n",
    "        optimal_w= w.T\n",
    "        optimal_b= b\n",
    "        return\n",
    "            \n",
    "    elif(iteration==max_iteration):\n",
    "        print(f'Convergence not happened within {max_iteration} iterations')\n",
    "        return \n",
    "    else:    \n",
    "        update_function(w_new,b_new,r,x,y,iteration) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_function1(w,b,r,x,y,iteration,batch_size,tolerance=0.0001,max_iteration=100000):\n",
    "    '''\n",
    "    To perform update function for SGD Optimization and store optimum value of W and B to the variables\n",
    "    '''\n",
    "    global optimal_w\n",
    "    global optimal_b\n",
    "    \n",
    "    for i in range(max_iteration):\n",
    "        iteration+=1\n",
    "        k=np.random.randint(0,high=len(x),size=batch_size) # Batch size\n",
    "        x1=x[k]\n",
    "        y1=y[k,np.newaxis]\n",
    "        w_new= w.T -(r * W_gradient(w,b,x1,y1))\n",
    "        w_new=w_new.T\n",
    "        b_new=b-(r * B_gradient(w,b,x1,y1))\n",
    "        \n",
    "        if(euclidean(w_new,w) <= tolerance and euclidean(b_new,b) <= tolerance):\n",
    "            print(f'\\n Converged after {iteration} Iterations.. :) ')\n",
    "            optimal_w= w.T\n",
    "            optimal_b= b\n",
    "            break\n",
    "    \n",
    "        elif(iteration==max_iteration):\n",
    "            print(f'\\n Convergence not happened within {max_iteration} iterations')\n",
    "            break \n",
    "    \n",
    "        else:    \n",
    "            w=w_new\n",
    "            b=b_new\n",
    "            r*=0.999\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_function(feats,class1,size=100):\n",
    "    '''\n",
    "    to calculate SGD for linear regression with batch = size\n",
    "    '''\n",
    "    global iteration\n",
    "    learning_rate =10**-2\n",
    "    weight=np.random.rand(1,(feats.shape[1]))\n",
    "    b=np.random.rand()\n",
    "    #print(weight.shape)\n",
    "    #print(b.shape)\n",
    "    iteration=0\n",
    "    update_function1(weight,b,learning_rate,feats,class1,iteration,size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_performance(y,y_hat):\n",
    "    '''\n",
    "    To Compute r^2 error and Mean squared error\n",
    "    '''\n",
    "    print(f'\\n R2 Score is {r2_score(y,y_hat)}')\n",
    "    print(f'\\n Mean Squared error is = {mean_squared_error(y_test,y_hat)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(x_test,y_test):\n",
    "    '''\n",
    "    To predict and measure the performance of test data with Optimal W obtained from Gradient function\n",
    "    '''\n",
    "    pred=(x_test.dot(optimal_w))+optimal_b\n",
    "    sgd_performance(y_test,pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Implemented program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Converged after 4929 Iterations.. :) \n"
     ]
    }
   ],
   "source": [
    "gradient_function(std_train,y_train,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal w is \n",
      " [[-1.00381125]\n",
      " [ 1.05528851]\n",
      " [-0.19997677]\n",
      " [ 0.84941216]\n",
      " [-1.53512172]\n",
      " [ 2.9944787 ]\n",
      " [-0.14821994]\n",
      " [-3.08029167]\n",
      " [ 2.11409331]\n",
      " [-1.58632589]\n",
      " [-1.98326815]\n",
      " [ 0.52641895]\n",
      " [-3.87854776]] \n",
      "\n",
      " and Optimal_b is 22.93860002860945\n"
     ]
    }
   ],
   "source": [
    "print(f'Optimal w is \\n {optimal_w} \\n\\n and Optimal_b is {optimal_b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " R2 Score is 0.6858200021185472\n",
      "\n",
      " Mean Squared error is = 22.70542604657475\n"
     ]
    }
   ],
   "source": [
    "predictor(std_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression Sklearn package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LinearRegression()\n",
    "lr.fit(std_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1=lr.predict(std_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.76048343651732\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_test,pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " R2 Score is 0.6850581608467723\n",
      "\n",
      " Mean Squared error is = 22.76048343651732\n"
     ]
    }
   ],
   "source": [
    "sgd_performance(y_test,pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision between Sklearn and my implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " By comparing the results from cell [20] and cell [24]. It is clear that my implementation of <i>SGD with <b>batch size 100 and tolerance as 0.0001 </b> is almost similar/slightly better to the results obtained from Sklearn package</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of our implemented SGD with different batch sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_analyser():\n",
    "    '''\n",
    "    To analyse result of SGD with various batch sizes.\n",
    "    '''\n",
    "    batch_list=[10,50,100,175,250]\n",
    "    for i in batch_list:\n",
    "        print('\\n ################################################################################')\n",
    "        print(f'\\n Batch Size = {i}')\n",
    "        gradient_function(std_train,y_train,i)\n",
    "        predictor(std_test,y_test)\n",
    "    print('\\n ################################################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ################################################################################\n",
      "\n",
      " Batch Size = 10\n",
      "\n",
      " Converged after 4929 Iterations.. :) \n",
      "\n",
      " R2 Score is 0.6853018337438443\n",
      "\n",
      " Mean Squared error is = 22.74287347731771\n",
      "\n",
      " ################################################################################\n",
      "\n",
      " Batch Size = 50\n",
      "\n",
      " Converged after 5296 Iterations.. :) \n",
      "\n",
      " R2 Score is 0.6847504832849436\n",
      "\n",
      " Mean Squared error is = 22.78271893901078\n",
      "\n",
      " ################################################################################\n",
      "\n",
      " Batch Size = 100\n",
      "\n",
      " Converged after 5194 Iterations.. :) \n",
      "\n",
      " R2 Score is 0.6854899340481515\n",
      "\n",
      " Mean Squared error is = 22.72927968529535\n",
      "\n",
      " ################################################################################\n",
      "\n",
      " Batch Size = 175\n",
      "\n",
      " Converged after 4352 Iterations.. :) \n",
      "\n",
      " R2 Score is 0.6857509480126176\n",
      "\n",
      " Mean Squared error is = 22.710416507157753\n",
      "\n",
      " ################################################################################\n",
      "\n",
      " Batch Size = 250\n",
      "\n",
      " Converged after 4470 Iterations.. :) \n",
      "\n",
      " R2 Score is 0.6857748648086174\n",
      "\n",
      " Mean Squared error is = 22.708688067898393\n",
      "\n",
      " ################################################################################\n"
     ]
    }
   ],
   "source": [
    "sgd_analyser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferences from above exercise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above analysis we can infer the below points,\n",
    "\n",
    "1.) With increase in batch size, number of iterations taken to converge decreases.\n",
    "\n",
    "2.) There is not much variation in performance scores between different batch sizes as it is clear that Stochastic gradient can produce faster convergence with very small batch size rather than the conventional GD where entire set of data will be considered.\n",
    "\n",
    "3.) When learning rate(r) is decreased on a faster rate in each iteration, it is producing minimum iteration for convergence, but the optimal_W is less accurate than the one obtained with the very slower decay.\n",
    "\n",
    "4.)Since we are not using any regulariser in this linear regression exercise, we don't need any cross validation data sets/any hyperparameter tuning part."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
